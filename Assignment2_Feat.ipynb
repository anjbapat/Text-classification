{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Assignment2_Feat.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSFD2OIdU6BS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pandas import DataFrame, read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54BxWeiLhYeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracting folder\n",
        "\n",
        "import requests\n",
        "\n",
        "filename = 'aclImdb_v1.tar.gz' \n",
        "url = u'http://ai.stanford.edu/~amaas/data/sentiment/' + filename \n",
        "r = requests.get(url)\n",
        "with open(filename, 'wb') as f: f.write(r.content)\n",
        "\n",
        "#...extract zip file\n",
        "import tarfile\n",
        "\n",
        "tar = tarfile.open(filename, mode='r')\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuvE4KEDU6BX",
        "colab_type": "text"
      },
      "source": [
        "### Problem 1: Creating function for Precision, Recall and F1score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkXqidV0U6BY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_precision(y_pred, y_test, debug = False):\n",
        "\n",
        "    # deal with npdarray\n",
        "\n",
        "    y_pred = list(y_pred)\n",
        "\n",
        "    y_test = list(y_test)\n",
        "\n",
        "\n",
        "    y_pred = list(map(int,[1 == l for l in y_pred]))# deal with None type\n",
        "\n",
        "    y_test = list(map(int,[1 == l for l in y_test]))# deal with None type\n",
        "    \n",
        "    n = len(y_pred);\n",
        "\n",
        "    true_positive = sum(y_pred[i]* y_test[i] for i in range(n))\n",
        "\n",
        "    if (0 == sum(y_pred)): return 0\n",
        "\n",
        "    return true_positive*1.0/sum(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkC7IEKLU6Ba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_recall(y_pred, y_test):\n",
        "\n",
        "    # deal with npdarray\n",
        "\n",
        "    y_pred = list(y_pred)\n",
        "\n",
        "    y_test = list(y_test)\n",
        "\n",
        "    n = len(y_pred);\n",
        "\n",
        "    y_pred = list(map(int,[1 == l for l in y_pred]))# deal with None type\n",
        "\n",
        "    y_test = list(map(int,[1 == l for l in y_test]))# deal with None type\n",
        "\n",
        "    true_positive = sum(y_pred[i]*y_test[i] for i in range(n))\n",
        "\n",
        "    if 0 == sum(y_test): return 0\n",
        "\n",
        "    return true_positive*1.0/sum(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc_Btu5LU6Bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_fscore(y_pred, y_test):\n",
        "\n",
        "\n",
        "    precision=get_precision(y_pred,y_test)\n",
        "\n",
        "    recall=get_recall(y_pred,y_test)\n",
        "\n",
        "    if precision==0 and recall==0:\n",
        "\n",
        "        return 0\n",
        "\n",
        "    fscore=2.0*precision*recall/(precision+recall)\n",
        "\n",
        "    return fscore"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8825sl_U6Bh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracting Data in train test files\n",
        "\n",
        "imdb_dir = 'aclImdb'\n",
        "train_dir = os.path.join(imdb_dir,'train')\n",
        "test_dir = os.path.join(imdb_dir,'test')\n",
        "labels = []\n",
        "texts = []\n",
        "\n",
        "test_labels = []\n",
        "test_texts = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzToidDXU6Bj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tagging data as positive and negative in train data\n",
        "\n",
        "for label_type in ['pos','neg']:\n",
        "    dir_name = os.path.join(train_dir,label_type)\n",
        "    for fname in os.listdir(dir_name):\n",
        "        if fname[-4:] == '.txt':\n",
        "            f = open(os.path.join(dir_name,fname),encoding=\"utf8\")\n",
        "            texts.append(f.read())\n",
        "            f.close()\n",
        "            if label_type == 'neg':\n",
        "                labels.append(0)\n",
        "            else:\n",
        "                labels.append(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFK4vOJkU6Bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tagging data as positive and negative in test data\n",
        "\n",
        "for label_type in ['pos','neg']:\n",
        "    dir_name = os.path.join(test_dir,label_type)\n",
        "    for fname in os.listdir(dir_name):\n",
        "        if fname[-4:] == '.txt':\n",
        "            f = open(os.path.join(dir_name,fname),encoding=\"utf8\")\n",
        "            test_texts.append(f.read())\n",
        "            f.close()\n",
        "            if label_type == 'neg':\n",
        "                test_labels.append(0)\n",
        "            else:\n",
        "                test_labels.append(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iXTed7yU6Bo",
        "colab_type": "code",
        "outputId": "703d9cc7-eb72-4db5-9322-fb22c72e88fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(f'Length of texts is {len(texts)}')\n",
        "print(f'Length of labels id {len(labels)}')\n",
        "print(f'Length of test_texts is {len(test_texts)}')\n",
        "print(f'Length of test_labels is {len(test_labels )}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of texts is 25000\n",
            "Length of labels id 25000\n",
            "Length of test_texts is 25000\n",
            "Length of test_labels is 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSoKB5QVU6Bs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_df = pd.DataFrame({'texts': texts,\n",
        "                        'labels':labels})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBJ0l4k2U6Bu",
        "colab_type": "code",
        "outputId": "0a94a615-71ee-40c4-ed6a-7a4821b8cdb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "texts_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(spoilers)&lt;br /&gt;&lt;br /&gt;I was blown away by this...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Joe Don Baker is one of a handful of actors wh...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I'd never seen an independent movie and I was ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ok, at the beginning it looked like \"Shrek\" - ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I fell in love with this silent action drama. ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               texts  labels\n",
              "0  (spoilers)<br /><br />I was blown away by this...       1\n",
              "1  Joe Don Baker is one of a handful of actors wh...       1\n",
              "2  I'd never seen an independent movie and I was ...       1\n",
              "3  Ok, at the beginning it looked like \"Shrek\" - ...       1\n",
              "4  I fell in love with this silent action drama. ...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5JSjfoXU6Bz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "positive = texts_df[texts_df['labels']==1]['texts']\n",
        "negative = texts_df[texts_df['labels']==0]['texts']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21ySSIE4U6B2",
        "colab_type": "text"
      },
      "source": [
        "### Problem 2: Majority Class Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HSf2AzgU6B3",
        "colab_type": "code",
        "outputId": "75052555-2506-4206-af48-b7aa46d440d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(texts_df.texts,texts_df.labels, test_size=0.3, random_state=0)\n",
        "print(X_test.shape,y_test.shape,X_train.shape,y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7500,) (7500,) (17500,) (17500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KYbGZ9jU6B6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.dummy import DummyClassifier       #this classifier selects the most frequent class in train data and fit on test data\n",
        "\n",
        "dummy_majority = DummyClassifier(strategy='most_frequent',random_state=0)\n",
        "dummy_majority.fit(X_train,y_train)\n",
        "\n",
        "y_pred = dummy_majority.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHc72INUUktN",
        "colab_type": "code",
        "outputId": "2cda7a04-6a0e-4947-a4de-02630a6bec3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#using function\n",
        "print(\"Precison:\",get_precision(y_pred,y_test))\n",
        "print(\"Recall:\",get_recall(y_pred,y_test))\n",
        "print(\"FScore:\",get_fscore(y_pred,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precison: 0\n",
            "Recall: 0.0\n",
            "FScore: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVlqMag5U6B9",
        "colab_type": "code",
        "outputId": "749540f8-bb4d-4b4a-fb6f-aef9923aae16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "#Using sklearn\n",
        "print(\"Precision: %0.2f\" %precision_score(y_test, y_pred , average=\"macro\"))\n",
        "print(\"Recall:  %0.2f\" %recall_score(y_test, y_pred , average=\"macro\"))\n",
        "print(\"F1-score:  %0.2f\" %f1_score(y_test, y_pred , average=\"macro\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.25\n",
            "Recall:  0.50\n",
            "F1-score:  0.33\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5GMHYPqnpbS",
        "colab_type": "code",
        "outputId": "338ce167-d0ae-4d89-9dfb-8c0afa4be5dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.49773333333333336"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvBRqWrrU6CG",
        "colab_type": "text"
      },
      "source": [
        "### Problem 3: Review Length Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byadNQpfU6CH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_df['text_length'] = texts_df['texts'].str.split().str.len()  # creating new variable for text length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6E19-LYU6CK",
        "colab_type": "code",
        "outputId": "c699393f-6a19-46c4-b225-67bf48e3397e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "texts_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>labels</th>\n",
              "      <th>text_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(spoilers)&lt;br /&gt;&lt;br /&gt;I was blown away by this...</td>\n",
              "      <td>1</td>\n",
              "      <td>140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Joe Don Baker is one of a handful of actors wh...</td>\n",
              "      <td>1</td>\n",
              "      <td>254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I'd never seen an independent movie and I was ...</td>\n",
              "      <td>1</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ok, at the beginning it looked like \"Shrek\" - ...</td>\n",
              "      <td>1</td>\n",
              "      <td>193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I fell in love with this silent action drama. ...</td>\n",
              "      <td>1</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               texts  labels  text_length\n",
              "0  (spoilers)<br /><br />I was blown away by this...       1          140\n",
              "1  Joe Don Baker is one of a handful of actors wh...       1          254\n",
              "2  I'd never seen an independent movie and I was ...       1           87\n",
              "3  Ok, at the beginning it looked like \"Shrek\" - ...       1          193\n",
              "4  I fell in love with this silent action drama. ...       1          113"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luAAZGFhoeIG",
        "colab_type": "code",
        "outputId": "17410bb3-59be-478b-89af-4ab057ec8171",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "texts_df['text_length'].max()  # maximum length of review in data is 2470"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2470"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xpz_dbccok30",
        "colab_type": "code",
        "outputId": "de3934f6-0119-4aca-dd2e-c0bd2eabedcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "texts_df['text_length'].min()   #min length of review in data is 10"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx9ppCFXU6CN",
        "colab_type": "text"
      },
      "source": [
        "1. Setting threshold of length 100 words, 1 if length greater than 100 else 0 (Selected 100 just to check how model is performing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_-Chy2-U6CO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_df['New_Labels'] = texts_df['text_length'].apply(lambda x: '1' if x>100 else '0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOxkdtM8U6CQ",
        "colab_type": "code",
        "outputId": "484e1423-9603-4075-e668-113738ca2984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "texts_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>labels</th>\n",
              "      <th>text_length</th>\n",
              "      <th>New_Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(spoilers)&lt;br /&gt;&lt;br /&gt;I was blown away by this...</td>\n",
              "      <td>1</td>\n",
              "      <td>140</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Joe Don Baker is one of a handful of actors wh...</td>\n",
              "      <td>1</td>\n",
              "      <td>254</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I'd never seen an independent movie and I was ...</td>\n",
              "      <td>1</td>\n",
              "      <td>87</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ok, at the beginning it looked like \"Shrek\" - ...</td>\n",
              "      <td>1</td>\n",
              "      <td>193</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I fell in love with this silent action drama. ...</td>\n",
              "      <td>1</td>\n",
              "      <td>113</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               texts  ...  New_Labels\n",
              "0  (spoilers)<br /><br />I was blown away by this...  ...           1\n",
              "1  Joe Don Baker is one of a handful of actors wh...  ...           1\n",
              "2  I'd never seen an independent movie and I was ...  ...           0\n",
              "3  Ok, at the beginning it looked like \"Shrek\" - ...  ...           1\n",
              "4  I fell in love with this silent action drama. ...  ...           1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I3dC_qpU6CT",
        "colab_type": "code",
        "outputId": "c64ff80c-6d23-4d4b-c16a-b8a6c600e275",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "## Splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts_df.texts,texts_df.New_Labels, test_size=0.3, random_state=0)\n",
        "print(X_test.shape,y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7500,) (7500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhqozbIOU6CW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Length_baseline1 = DummyClassifier(strategy='stratified',random_state=0)\n",
        "Length_baseline1.fit(X_train,y_train)\n",
        "\n",
        "y_pred = Length_baseline1.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuCL2ajtU6Cd",
        "colab_type": "code",
        "outputId": "27bc6c98-3723-4f20-957b-8b24473b8951",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Evaluation with pre-defined function\n",
        "print(\"Precision: %0.2f\" %precision_score(y_test, y_pred , average=\"macro\"))\n",
        "print(\"Recall:  %0.2f\" %recall_score(y_test, y_pred , average=\"macro\"))\n",
        "print(\"F1-score:  %0.2f\" %f1_score(y_test, y_pred , average=\"macro\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.50\n",
            "Recall:  0.50\n",
            "F1-score:  0.50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P3ALbVhyEgF",
        "colab_type": "code",
        "outputId": "ae9d3b35-13f7-41b4-ef4c-69856e75b5c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(\"Precison:\",get_precision(y_pred,y_test))\n",
        "print(\"Recall:\",get_recall(y_pred,y_test))\n",
        "print(\"FScore:\",get_fscore(y_pred,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precison: 0\n",
            "Recall: 0\n",
            "FScore: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEpiOIJBpfmd",
        "colab_type": "text"
      },
      "source": [
        "2. Setting threshold of length 500 words, 1 if length greater than 500 else 0 (Choosing 500 because disappointed people usually write a big review)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H18lYY3CU6Ci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_df['New_Labels'] = texts_df['text_length'].apply(lambda x: '1' if x>500 else '0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X_71fYgU6Cl",
        "colab_type": "code",
        "outputId": "3f303a18-bd29-4c71-d1d7-3295a6ea5df0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "texts_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>labels</th>\n",
              "      <th>text_length</th>\n",
              "      <th>New_Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(spoilers)&lt;br /&gt;&lt;br /&gt;I was blown away by this...</td>\n",
              "      <td>1</td>\n",
              "      <td>140</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Joe Don Baker is one of a handful of actors wh...</td>\n",
              "      <td>1</td>\n",
              "      <td>254</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I'd never seen an independent movie and I was ...</td>\n",
              "      <td>1</td>\n",
              "      <td>87</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ok, at the beginning it looked like \"Shrek\" - ...</td>\n",
              "      <td>1</td>\n",
              "      <td>193</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I fell in love with this silent action drama. ...</td>\n",
              "      <td>1</td>\n",
              "      <td>113</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               texts  ...  New_Labels\n",
              "0  (spoilers)<br /><br />I was blown away by this...  ...           0\n",
              "1  Joe Don Baker is one of a handful of actors wh...  ...           0\n",
              "2  I'd never seen an independent movie and I was ...  ...           0\n",
              "3  Ok, at the beginning it looked like \"Shrek\" - ...  ...           0\n",
              "4  I fell in love with this silent action drama. ...  ...           0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFfilXErU6Cq",
        "colab_type": "code",
        "outputId": "e8eb3959-0b19-4930-d6ae-e25e1db0429c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "## Splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts_df.texts,texts_df.New_Labels, test_size=0.3, random_state=0)\n",
        "print(X_test.shape,y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7500,) (7500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD0peaVhU6Ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Length_baseline2 = DummyClassifier(strategy='uniform',random_state=0)\n",
        "Length_baseline2.fit(X_train,y_train)\n",
        "\n",
        "y_pred = Length_baseline2.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip9xTtDyU6Cx",
        "colab_type": "code",
        "outputId": "581fb17f-4e22-4737-ffc8-6d60beaee497",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "Evaluation with pre-defined function\n",
        "print(\"Precision: %0.2f\" %precision_score(y_test, y_pred , average=\"macro\"))\n",
        "print(\"Recall:  %0.2f\" %recall_score(y_test, y_pred , average=\"macro\"))\n",
        "print(\"F1-score:  %0.2f\" %f1_score(y_test, y_pred , average=\"macro\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.50\n",
            "Recall:  0.49\n",
            "F1-score:  0.39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZxTnsSeyLWj",
        "colab_type": "code",
        "outputId": "ae253a27-aa93-4189-a89d-cde19c8d4735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(\"Precison:\",get_precision(y_pred,y_test))\n",
        "print(\"Recall:\",get_recall(y_pred,y_test))\n",
        "print(\"FScore:\",get_fscore(y_pred,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precison: 0\n",
            "Recall: 0\n",
            "FScore: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYd1TgeXp4to",
        "colab_type": "text"
      },
      "source": [
        "3. Setting threshold of length 15 words, 1 if length greater than 15 else 0 (Choosing 15 words because people sometimes write a review short)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUCt8UTvU6C2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_df['New_Labels'] = texts_df['text_length'].apply(lambda x: '1' if x>15 else '0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBlxvcSlU6C4",
        "colab_type": "code",
        "outputId": "3093b17f-3a91-4453-e056-df7a1847dfca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "## Splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts_df.texts,texts_df.New_Labels, test_size=0.3, random_state=0)\n",
        "print(X_test.shape,y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7500,) (7500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhIGbMx4U6C8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Length_baseline3 = DummyClassifier(strategy='uniform',random_state=0)\n",
        "Length_baseline3.fit(X_train,y_train)\n",
        "\n",
        "y_pred = Length_baseline3.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9URFwrnU6C-",
        "colab_type": "code",
        "outputId": "8789d3df-3b05-4754-b981-c5035aa86e05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(\"Precision: %0.2f\" %precision_score(y_test, y_pred , average=\"macro\"))\n",
        "print(\"Recall:  %0.2f\" %recall_score(y_test, y_pred , average=\"macro\"))\n",
        "print(\"F1-score:  %0.2f\" %f1_score(y_test, y_pred , average=\"macro\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.50\n",
            "Recall:  0.49\n",
            "F1-score:  0.39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efz_PooTyQcn",
        "colab_type": "code",
        "outputId": "14f47376-9c1c-47da-e5d8-60219161c11a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(\"Precison:\",get_precision(y_pred,y_test))\n",
        "print(\"Recall:\",get_recall(y_pred,y_test))\n",
        "print(\"FScore:\",get_fscore(y_pred,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precison: 0\n",
            "Recall: 0\n",
            "FScore: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa9oLNcFU6C_",
        "colab_type": "text"
      },
      "source": [
        "### Problem 4: Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgrwnYZsU6DA",
        "colab_type": "code",
        "outputId": "af209a77-fd20-4e50-86c2-b887738c4f97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "texts_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>labels</th>\n",
              "      <th>text_length</th>\n",
              "      <th>New_Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(spoilers)&lt;br /&gt;&lt;br /&gt;I was blown away by this...</td>\n",
              "      <td>1</td>\n",
              "      <td>140</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Joe Don Baker is one of a handful of actors wh...</td>\n",
              "      <td>1</td>\n",
              "      <td>254</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I'd never seen an independent movie and I was ...</td>\n",
              "      <td>1</td>\n",
              "      <td>87</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ok, at the beginning it looked like \"Shrek\" - ...</td>\n",
              "      <td>1</td>\n",
              "      <td>193</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I fell in love with this silent action drama. ...</td>\n",
              "      <td>1</td>\n",
              "      <td>113</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               texts  ...  New_Labels\n",
              "0  (spoilers)<br /><br />I was blown away by this...  ...           1\n",
              "1  Joe Don Baker is one of a handful of actors wh...  ...           1\n",
              "2  I'd never seen an independent movie and I was ...  ...           1\n",
              "3  Ok, at the beginning it looked like \"Shrek\" - ...  ...           1\n",
              "4  I fell in love with this silent action drama. ...  ...           1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubzzfprRV8V6",
        "colab_type": "code",
        "outputId": "2e04881b-6733-4aa4-9e49-c85a4591c48e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "texts_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yPbzk6o-fH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using sample to run Naive Bayes because it fails on my laptop with memory error. Tried on colab, hadoop cloud but no luck.\n",
        "import random\n",
        "text_sample= texts_df.sample(n=10000,replace=False, random_state=None)\n",
        "#data.iloc[0:5] # first five rows of dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka41wZNa_y2V",
        "colab_type": "code",
        "outputId": "32ae0dfa-7efd-40c1-e62a-3f66c72a71ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "text_sample.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e52-JGwtHYXA",
        "colab_type": "code",
        "outputId": "efab047a-b4b6-4b73-c168-e463593e07de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "text_sample.head"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                                    texts  ...  New_Labels\n",
              "12580  I got this movie in the $5 bin at walmart. I w...  ...           1\n",
              "2454   Here's the kind of love story that I do enjoy ...  ...           1\n",
              "21519  This movie was horrible. I swear they didn't e...  ...           1\n",
              "24787  This film should have never been made. Honestl...  ...           1\n",
              "9083   Having seen and loved Greg Lombardo's most rec...  ...           1\n",
              "24810  C'mon guys some previous reviewers have nearly...  ...           1\n",
              "15317  I won't add to the plot reviews, it's not very...  ...           1\n",
              "9361   Made in 1946 and released in 1948, The Lady an...  ...           1\n",
              "10956  I watched this movie a couple of days ago in a...  ...           1\n",
              "6305   I'm surprised how many people give this move l...  ...           1\n",
              "18232  The cover on the DVD and disc is freaking awes...  ...           1\n",
              "16218  My wife and I just finished watching BÃ»su AKA ...  ...           1\n",
              "18719  Gee, what a heck of a movie!... I said I wante...  ...           1\n",
              "4404   As the film opens, two thugs kill another thug...  ...           1\n",
              "21923  Dysfunctional family goes home for the holiday...  ...           1\n",
              "16169  How has this piece of crap stayed on TV this l...  ...           1\n",
              "16703  A young boy sees his mother getting killed and...  ...           1\n",
              "15648  For a fan series, I must admit that Hidden Fro...  ...           1\n",
              "4990   When I was born, this television series was th...  ...           1\n",
              "18353  I'm not sure what Diane Silver was thinking wh...  ...           1\n",
              "13615  Like Freddy's Revenge, this sequel takes a pre...  ...           1\n",
              "18635  Michael Williams, who works for BBC, finds a s...  ...           1\n",
              "8648   Karen (Sarah Michelle Gellar), an exchange stu...  ...           1\n",
              "12405  I can admit that the screenplay isn't very goo...  ...           1\n",
              "2843   Had a bad day? Dog bit the mailman? Car wouldn...  ...           1\n",
              "16111  More wide-eyed, hysterical 50s hyper-cheerfuln...  ...           1\n",
              "2612   Given the nature and origin of the 11 filmaker...  ...           1\n",
              "19845  The only aspect of this film that saves it fro...  ...           1\n",
              "1094   I love this movie. My friend Marcus and I were...  ...           1\n",
              "711    I saw this film a couple of weeks ago, and it'...  ...           1\n",
              "...                                                  ...  ...         ...\n",
              "12563  I'm only rating this film as a 3 out of pity b...  ...           1\n",
              "16440  On the surface, this movie would appear to dea...  ...           1\n",
              "11174  A Bug's Life is a very good animated feature. ...  ...           1\n",
              "20599  I Am Curious is really two films in one - half...  ...           1\n",
              "13301  WOW! Pretty terrible stuff. The Richard Burton...  ...           1\n",
              "22797  awful, just awful! my old room mate used to wa...  ...           1\n",
              "5053   De Sica is becoming one of my favorite directo...  ...           1\n",
              "7402   Well, well....Roeg touched a bit of a nerve th...  ...           1\n",
              "22879  Anyone who has said that it's better than Host...  ...           1\n",
              "2973   I saw the film twice in the space of one week,...  ...           1\n",
              "3308   The story is being told fluidly. There are no ...  ...           1\n",
              "707    Wasn't sure what to expect from this film. I l...  ...           1\n",
              "13577  One scene demonstrates the mentality of \"Termi...  ...           1\n",
              "17718  I thought I was going to watch a scary movie.....  ...           1\n",
              "9713   I have been a fan of Pushing Daisies since the...  ...           1\n",
              "16926  When I saw this trailer on TV I was surprised....  ...           1\n",
              "16511  Are you kidding me?! A show highlighting someo...  ...           1\n",
              "14666  I just read a review defending this film becau...  ...           1\n",
              "24588  That is the best way I can describe this movie...  ...           1\n",
              "16361  I like Billy Crystal, and I thought it would b...  ...           1\n",
              "2968   The first 2 parts seek to reduce to absurdity ...  ...           1\n",
              "17320  I watched this film a long time ago (aprox 10 ...  ...           1\n",
              "22479  Oh man, does this movie ever bite! If you were...  ...           1\n",
              "20417  This movie is terrible. The suspense is spent ...  ...           1\n",
              "10319  An enjoyable game, which offers fun and easy g...  ...           1\n",
              "11800  \"Life stinks\" is a parody of life and death, h...  ...           1\n",
              "10340  Ossessione, adapted loosely (or if it is as lo...  ...           1\n",
              "23795  Shazbot, is this embarrassing. In fact, here's...  ...           1\n",
              "7838   I watched \"Elephant Walk\" for the first time i...  ...           1\n",
              "23846  You've gotta hand it to Steven Seagal: whateve...  ...           1\n",
              "\n",
              "[10000 rows x 4 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp1JahYhfzht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the documents\n",
        "documents = text_sample['texts']\n",
        "# Import the count vectorizer and initialize it\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vector = CountVectorizer()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56n92eo9qPF7",
        "colab_type": "code",
        "outputId": "b62741cb-53ee-49be-dfdc-cdc939c2bab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "documents.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4214     The man who directed 'The Third Man' also dire...\n",
              "4031     I had pleasure to watch the short film \"The Cu...\n",
              "20933    Liongate has yet to prove itself. Every single...\n",
              "4937     Well, I guess I'm emotionally attached to this...\n",
              "2429     I have watched this movie well over 100-200 ti...\n",
              "Name: texts, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHvQR8QAqX9J",
        "colab_type": "code",
        "outputId": "ccd2dbd9-1021-4537-c7d0-f81e4d619c63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "count_vector.fit(documents)\n",
        "names = count_vector.get_feature_names()\n",
        "names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['00',\n",
              " '000',\n",
              " '000s',\n",
              " '001',\n",
              " '003830',\n",
              " '007',\n",
              " '0080',\n",
              " '0083',\n",
              " '00am',\n",
              " '00pm',\n",
              " '00s',\n",
              " '01',\n",
              " '02',\n",
              " '020410',\n",
              " '03',\n",
              " '04',\n",
              " '05',\n",
              " '050',\n",
              " '06',\n",
              " '07',\n",
              " '08',\n",
              " '089',\n",
              " '08th',\n",
              " '09',\n",
              " '0s',\n",
              " '10',\n",
              " '100',\n",
              " '1000',\n",
              " '1000s',\n",
              " '1001',\n",
              " '100s',\n",
              " '100x',\n",
              " '100yards',\n",
              " '101',\n",
              " '101st',\n",
              " '102',\n",
              " '103',\n",
              " '104',\n",
              " '1040s',\n",
              " '105',\n",
              " '106',\n",
              " '107',\n",
              " '108',\n",
              " '109',\n",
              " '10p',\n",
              " '10s',\n",
              " '10th',\n",
              " '10x',\n",
              " '11',\n",
              " '110',\n",
              " '11001001',\n",
              " '112',\n",
              " '1138',\n",
              " '1146',\n",
              " '115',\n",
              " '116',\n",
              " '117',\n",
              " '11f',\n",
              " '11m',\n",
              " '11th',\n",
              " '12',\n",
              " '120',\n",
              " '1200',\n",
              " '1201',\n",
              " '1202',\n",
              " '123',\n",
              " '12383499143743701',\n",
              " '127',\n",
              " '128',\n",
              " '12m',\n",
              " '12mm',\n",
              " '12th',\n",
              " '13',\n",
              " '130',\n",
              " '1300',\n",
              " '1300s',\n",
              " '131',\n",
              " '1318',\n",
              " '134',\n",
              " '135',\n",
              " '135m',\n",
              " '138',\n",
              " '13k',\n",
              " '13s',\n",
              " '13th',\n",
              " '14',\n",
              " '140',\n",
              " '1408',\n",
              " '140hp',\n",
              " '142',\n",
              " '1454',\n",
              " '146',\n",
              " '1473',\n",
              " '14a',\n",
              " '14s',\n",
              " '14th',\n",
              " '14Ã¨me',\n",
              " '15',\n",
              " '150',\n",
              " '1500',\n",
              " '1500s',\n",
              " '150m',\n",
              " '1547',\n",
              " '156',\n",
              " '1561',\n",
              " '157',\n",
              " '158',\n",
              " '1594',\n",
              " '15mins',\n",
              " '15th',\n",
              " '16',\n",
              " '160',\n",
              " '1600',\n",
              " '1600s',\n",
              " '161',\n",
              " '1610',\n",
              " '163',\n",
              " '165',\n",
              " '166',\n",
              " '1660s',\n",
              " '168',\n",
              " '1692',\n",
              " '16mm',\n",
              " '16s',\n",
              " '16th',\n",
              " '16Ã¨me',\n",
              " '16Ã©me',\n",
              " '17',\n",
              " '1700',\n",
              " '1701',\n",
              " '175',\n",
              " '177',\n",
              " '1775',\n",
              " '1794',\n",
              " '17th',\n",
              " '18',\n",
              " '180',\n",
              " '1800',\n",
              " '1800mph',\n",
              " '1800s',\n",
              " '1801',\n",
              " '1812',\n",
              " '1816',\n",
              " '1820',\n",
              " '1830',\n",
              " '1832',\n",
              " '1836',\n",
              " '1838',\n",
              " '1839',\n",
              " '1840',\n",
              " '1840s',\n",
              " '1844',\n",
              " '1846',\n",
              " '1847',\n",
              " '185',\n",
              " '1850',\n",
              " '1850s',\n",
              " '1853',\n",
              " '1854',\n",
              " '1855',\n",
              " '1859',\n",
              " '1860',\n",
              " '1861',\n",
              " '1862',\n",
              " '1863',\n",
              " '1876',\n",
              " '188',\n",
              " '1880',\n",
              " '1881',\n",
              " '1886',\n",
              " '1887',\n",
              " '1888',\n",
              " '1889',\n",
              " '1890',\n",
              " '1890s',\n",
              " '1892',\n",
              " '1893',\n",
              " '1894',\n",
              " '1895',\n",
              " '1896',\n",
              " '1897',\n",
              " '1898',\n",
              " '1899',\n",
              " '18a',\n",
              " '18th',\n",
              " '19',\n",
              " '1900',\n",
              " '1900s',\n",
              " '1902',\n",
              " '1908',\n",
              " '1909',\n",
              " '1910',\n",
              " '1910s',\n",
              " '1911',\n",
              " '1912',\n",
              " '1913',\n",
              " '1914',\n",
              " '1915',\n",
              " '1916',\n",
              " '1917',\n",
              " '1918',\n",
              " '1919',\n",
              " '192',\n",
              " '1920',\n",
              " '1920ies',\n",
              " '1920s',\n",
              " '1921',\n",
              " '1922',\n",
              " '1923',\n",
              " '1924',\n",
              " '1925',\n",
              " '1926',\n",
              " '1927',\n",
              " '1928',\n",
              " '1929',\n",
              " '1930',\n",
              " '1930ies',\n",
              " '1930s',\n",
              " '1931',\n",
              " '1932',\n",
              " '1933',\n",
              " '1934',\n",
              " '1935',\n",
              " '1936',\n",
              " '1937',\n",
              " '1938',\n",
              " '1939',\n",
              " '1940',\n",
              " '1940s',\n",
              " '1941',\n",
              " '1942',\n",
              " '1943',\n",
              " '1944',\n",
              " '1945',\n",
              " '1946',\n",
              " '1947',\n",
              " '1948',\n",
              " '1949',\n",
              " '1949er',\n",
              " '1950',\n",
              " '1950s',\n",
              " '1951',\n",
              " '1952',\n",
              " '1953',\n",
              " '1954',\n",
              " '1955',\n",
              " '1956',\n",
              " '1957',\n",
              " '1958',\n",
              " '1959',\n",
              " '1960',\n",
              " '1960s',\n",
              " '1961',\n",
              " '1962',\n",
              " '1963',\n",
              " '1964',\n",
              " '1965',\n",
              " '1966',\n",
              " '1967',\n",
              " '1968',\n",
              " '1969',\n",
              " '1970',\n",
              " '1970s',\n",
              " '1971',\n",
              " '1972',\n",
              " '1973',\n",
              " '1974',\n",
              " '1975',\n",
              " '1976',\n",
              " '1977',\n",
              " '1978',\n",
              " '1979',\n",
              " '19796',\n",
              " '1980',\n",
              " '1980ies',\n",
              " '1980s',\n",
              " '1981',\n",
              " '1982',\n",
              " '1983',\n",
              " '1984',\n",
              " '1984ish',\n",
              " '1985',\n",
              " '1986',\n",
              " '1987',\n",
              " '1988',\n",
              " '1989',\n",
              " '1990',\n",
              " '1990s',\n",
              " '1991',\n",
              " '1992',\n",
              " '1993',\n",
              " '1994',\n",
              " '1995',\n",
              " '1996',\n",
              " '1997',\n",
              " '1998',\n",
              " '1999',\n",
              " '19th',\n",
              " '1h',\n",
              " '1hr',\n",
              " '1mln',\n",
              " '1o',\n",
              " '1s',\n",
              " '1st',\n",
              " '20',\n",
              " '200',\n",
              " '2000',\n",
              " '20000',\n",
              " '20001',\n",
              " '2000ad',\n",
              " '2000s',\n",
              " '2001',\n",
              " '2002',\n",
              " '2003',\n",
              " '2004',\n",
              " '2005',\n",
              " '2006',\n",
              " '2007',\n",
              " '2008',\n",
              " '2009',\n",
              " '200ft',\n",
              " '2010',\n",
              " '2012',\n",
              " '2017',\n",
              " '2020',\n",
              " '2022',\n",
              " '2030',\n",
              " '2031',\n",
              " '2033',\n",
              " '2036',\n",
              " '2040',\n",
              " '2044',\n",
              " '2047',\n",
              " '2053',\n",
              " '2054',\n",
              " '206',\n",
              " '209',\n",
              " '2090',\n",
              " '20c',\n",
              " '20ft',\n",
              " '20minutes',\n",
              " '20p',\n",
              " '20s',\n",
              " '20th',\n",
              " '20ties',\n",
              " '20year',\n",
              " '20yrs',\n",
              " '21',\n",
              " '210',\n",
              " '21699',\n",
              " '21st',\n",
              " '22',\n",
              " '2200',\n",
              " '2210',\n",
              " '22101',\n",
              " '225',\n",
              " '22d',\n",
              " '22h45',\n",
              " '22nd',\n",
              " '23',\n",
              " '233',\n",
              " '237',\n",
              " '23d',\n",
              " '23rd',\n",
              " '24',\n",
              " '241',\n",
              " '242',\n",
              " '248',\n",
              " '25',\n",
              " '250',\n",
              " '25million',\n",
              " '25th',\n",
              " '25yo',\n",
              " '25yrs',\n",
              " '26',\n",
              " '260',\n",
              " '2600',\n",
              " '262',\n",
              " '26th',\n",
              " '27',\n",
              " '270',\n",
              " '272',\n",
              " '273',\n",
              " '274',\n",
              " '2772',\n",
              " '27x41',\n",
              " '28',\n",
              " '28th',\n",
              " '29',\n",
              " '29th',\n",
              " '2am',\n",
              " '2d',\n",
              " '2h',\n",
              " '2h30',\n",
              " '2hours',\n",
              " '2hrs',\n",
              " '2nd',\n",
              " '2pac',\n",
              " '2x4',\n",
              " '30',\n",
              " '300',\n",
              " '3000',\n",
              " '300ad',\n",
              " '300lbs',\n",
              " '30am',\n",
              " '30ish',\n",
              " '30k',\n",
              " '30min',\n",
              " '30mins',\n",
              " '30s',\n",
              " '30th',\n",
              " '30ties',\n",
              " '31',\n",
              " '31st',\n",
              " '32',\n",
              " '3200',\n",
              " '320x180',\n",
              " '32lb',\n",
              " '33',\n",
              " '33m',\n",
              " '34',\n",
              " '345',\n",
              " '34th',\n",
              " '35',\n",
              " '350',\n",
              " '35mins',\n",
              " '35mm',\n",
              " '35yr',\n",
              " '36',\n",
              " '360',\n",
              " '365',\n",
              " '36th',\n",
              " '37',\n",
              " '372',\n",
              " '378',\n",
              " '38',\n",
              " '39',\n",
              " '3d',\n",
              " '3dvd',\n",
              " '3k',\n",
              " '3lbs',\n",
              " '3m',\n",
              " '3p',\n",
              " '3pm',\n",
              " '3po',\n",
              " '3rd',\n",
              " '3rds',\n",
              " '3th',\n",
              " '3x5',\n",
              " '40',\n",
              " '400',\n",
              " '4000',\n",
              " '409',\n",
              " '40mph',\n",
              " '40s',\n",
              " '40th',\n",
              " '41',\n",
              " '42',\n",
              " '425',\n",
              " '428',\n",
              " '42nd',\n",
              " '43',\n",
              " '44',\n",
              " '440',\n",
              " '45',\n",
              " '450',\n",
              " '451',\n",
              " '454',\n",
              " '45min',\n",
              " '46',\n",
              " '465',\n",
              " '47',\n",
              " '47s',\n",
              " '48',\n",
              " '480m',\n",
              " '48hrs',\n",
              " '49',\n",
              " '498',\n",
              " '4am',\n",
              " '4cylinder',\n",
              " '4h',\n",
              " '4m',\n",
              " '4pm',\n",
              " '4th',\n",
              " '4ward',\n",
              " '4x4',\n",
              " '50',\n",
              " '500',\n",
              " '5000',\n",
              " '500000',\n",
              " '500db',\n",
              " '500lbs',\n",
              " '50ish',\n",
              " '50k',\n",
              " '50min',\n",
              " '50s',\n",
              " '50th',\n",
              " '51',\n",
              " '51st',\n",
              " '52',\n",
              " '5200',\n",
              " '52s',\n",
              " '53',\n",
              " '53m',\n",
              " '54',\n",
              " '5400',\n",
              " '540i',\n",
              " '55',\n",
              " '55th',\n",
              " '56',\n",
              " '57',\n",
              " '571',\n",
              " '578',\n",
              " '57d',\n",
              " '58',\n",
              " '59',\n",
              " '5hrs',\n",
              " '5ive',\n",
              " '5million',\n",
              " '5mins',\n",
              " '5th',\n",
              " '60',\n",
              " '600',\n",
              " '6000',\n",
              " '607',\n",
              " '608',\n",
              " '60ish',\n",
              " '60s',\n",
              " '60th',\n",
              " '61',\n",
              " '62',\n",
              " '6200',\n",
              " '62229249',\n",
              " '63',\n",
              " '64',\n",
              " '65',\n",
              " '65m',\n",
              " '66',\n",
              " '666',\n",
              " '66er',\n",
              " '67',\n",
              " '6723',\n",
              " '67th',\n",
              " '68',\n",
              " '69',\n",
              " '69th',\n",
              " '6b',\n",
              " '6million',\n",
              " '6pm',\n",
              " '6th',\n",
              " '70',\n",
              " '700',\n",
              " '701',\n",
              " '707',\n",
              " '70m',\n",
              " '70mm',\n",
              " '70s',\n",
              " '71',\n",
              " '72',\n",
              " '72nd',\n",
              " '73',\n",
              " '735',\n",
              " '737',\n",
              " '74',\n",
              " '747',\n",
              " '74th',\n",
              " '75',\n",
              " '750',\n",
              " '75054',\n",
              " '76',\n",
              " '77',\n",
              " '78',\n",
              " '788',\n",
              " '79',\n",
              " '79th',\n",
              " '7eventy',\n",
              " '7mm',\n",
              " '7th',\n",
              " '80',\n",
              " '800',\n",
              " '8000',\n",
              " '80s',\n",
              " '81',\n",
              " '817',\n",
              " '82',\n",
              " '8217',\n",
              " '83',\n",
              " '84',\n",
              " '84f',\n",
              " '84s',\n",
              " '85',\n",
              " '86',\n",
              " '86s',\n",
              " '87',\n",
              " '8700',\n",
              " '878',\n",
              " '87minutes',\n",
              " '88',\n",
              " '89',\n",
              " '89s',\n",
              " '8bit',\n",
              " '8ftdf',\n",
              " '8k',\n",
              " '8mm',\n",
              " '8p',\n",
              " '8pm',\n",
              " '8th',\n",
              " '8u',\n",
              " '8Â½',\n",
              " '90',\n",
              " '900',\n",
              " '9000',\n",
              " '90210',\n",
              " '90mins',\n",
              " '90s',\n",
              " '91',\n",
              " '911',\n",
              " '917',\n",
              " '92',\n",
              " '921',\n",
              " '93',\n",
              " '937',\n",
              " '94',\n",
              " '94s',\n",
              " '95',\n",
              " '95th',\n",
              " '96',\n",
              " '97',\n",
              " '978',\n",
              " '98',\n",
              " '987',\n",
              " '98minutes',\n",
              " '99',\n",
              " '999',\n",
              " '99cents',\n",
              " '99p',\n",
              " '99Â½',\n",
              " '9_',\n",
              " '9am',\n",
              " '9as',\n",
              " '9do',\n",
              " '9ers',\n",
              " '9is',\n",
              " '9pm',\n",
              " '9th',\n",
              " '____',\n",
              " '_____',\n",
              " '______',\n",
              " '____________________________________',\n",
              " '_am_',\n",
              " '_anything_',\n",
              " '_apocalyptically',\n",
              " '_as',\n",
              " '_atlantis',\n",
              " '_atlantis_',\n",
              " '_attack',\n",
              " '_by',\n",
              " '_dr',\n",
              " '_everything_',\n",
              " '_ex_executives',\n",
              " '_extremeley_',\n",
              " '_film_',\n",
              " '_get_',\n",
              " '_have_',\n",
              " '_i_',\n",
              " '_is_',\n",
              " '_les',\n",
              " '_new',\n",
              " '_plan',\n",
              " '_real_',\n",
              " '_really_is_',\n",
              " '_so_much_',\n",
              " '_spiritited',\n",
              " '_the',\n",
              " '_the_lost_empire_',\n",
              " '_there',\n",
              " '_they_',\n",
              " '_toy',\n",
              " '_twice',\n",
              " '_undertow_',\n",
              " '_very_',\n",
              " '_voice_',\n",
              " '_want_',\n",
              " 'a1',\n",
              " 'a10',\n",
              " 'aa',\n",
              " 'aaa',\n",
              " 'aaaaaaah',\n",
              " 'aaaaatch',\n",
              " 'aaaarrgh',\n",
              " 'aaargh',\n",
              " 'aaaugh',\n",
              " 'aachen',\n",
              " 'aag',\n",
              " 'aage',\n",
              " 'aahhh',\n",
              " 'aaja',\n",
              " 'aakash',\n",
              " 'aaker',\n",
              " 'aakrosh',\n",
              " 'aames',\n",
              " 'aankhen',\n",
              " 'aapke',\n",
              " 'aardman',\n",
              " 'aargh',\n",
              " 'aaron',\n",
              " 'aarp',\n",
              " 'aarrrgh',\n",
              " 'aatish',\n",
              " 'aavjo',\n",
              " 'aaww',\n",
              " 'ab',\n",
              " 'aback',\n",
              " 'abandon',\n",
              " 'abandoned',\n",
              " 'abandoning',\n",
              " 'abandonment',\n",
              " 'abandons',\n",
              " 'abanks',\n",
              " 'abashed',\n",
              " 'abatement',\n",
              " 'abattoirs',\n",
              " 'abbas',\n",
              " 'abbasi',\n",
              " 'abbey',\n",
              " 'abbie',\n",
              " 'abbot',\n",
              " 'abbots',\n",
              " 'abbott',\n",
              " 'abbreviated',\n",
              " 'abby',\n",
              " 'abc',\n",
              " 'abdomen',\n",
              " 'abdominal',\n",
              " 'abdu',\n",
              " 'abduct',\n",
              " 'abducted',\n",
              " 'abducting',\n",
              " 'abduction',\n",
              " 'abductor',\n",
              " 'abducts',\n",
              " 'abdul',\n",
              " 'abdullah',\n",
              " 'abe',\n",
              " 'abel',\n",
              " 'abercrombie',\n",
              " 'abernathy',\n",
              " 'aberrant',\n",
              " 'aberration',\n",
              " 'aberystwyth',\n",
              " 'abets',\n",
              " 'abetted',\n",
              " 'abeyance',\n",
              " 'abhay',\n",
              " 'abhishek',\n",
              " 'abhor',\n",
              " 'abhorrence',\n",
              " 'abhorrent',\n",
              " 'abhors',\n",
              " 'abi',\n",
              " 'abides',\n",
              " 'abiding',\n",
              " 'abigail',\n",
              " 'abilities',\n",
              " 'ability',\n",
              " 'abishai',\n",
              " 'abishek',\n",
              " 'abject',\n",
              " 'able',\n",
              " 'ably',\n",
              " 'abner',\n",
              " 'abnormal',\n",
              " 'abnormally',\n",
              " 'abo',\n",
              " 'aboard',\n",
              " 'abode',\n",
              " 'abodes',\n",
              " 'abolish',\n",
              " 'abolished',\n",
              " 'abolitionists',\n",
              " 'abominable',\n",
              " 'abominably',\n",
              " 'abomination',\n",
              " 'abominations',\n",
              " 'abominator',\n",
              " 'aboooot',\n",
              " 'aborigin',\n",
              " 'aboriginal',\n",
              " 'aboriginals',\n",
              " 'aborigine',\n",
              " 'aborigines',\n",
              " 'aboriginies',\n",
              " 'aborigins',\n",
              " 'aborigone',\n",
              " 'abort',\n",
              " 'aborted',\n",
              " 'aborting',\n",
              " 'abortion',\n",
              " 'abortionist',\n",
              " 'abortionists',\n",
              " 'abortions',\n",
              " 'abortive',\n",
              " 'aborts',\n",
              " 'abos',\n",
              " 'abott',\n",
              " 'abound',\n",
              " 'abounds',\n",
              " 'about',\n",
              " 'above',\n",
              " 'abracadabrantesque',\n",
              " 'abraham',\n",
              " 'abrahams',\n",
              " 'abrahms',\n",
              " 'abrams',\n",
              " 'abrasive',\n",
              " 'abre',\n",
              " 'abreast',\n",
              " 'abridged',\n",
              " 'abril',\n",
              " 'abroad',\n",
              " 'abrupt',\n",
              " 'abruptly',\n",
              " 'abs',\n",
              " 'abscond',\n",
              " 'absconded',\n",
              " 'absconding',\n",
              " 'absence',\n",
              " 'absences',\n",
              " 'absent',\n",
              " 'absentee',\n",
              " 'absentminded',\n",
              " 'absentmindedly',\n",
              " 'absolute',\n",
              " 'absolutelly',\n",
              " 'absolutely',\n",
              " 'absolutey',\n",
              " 'absolution',\n",
              " 'absolutley',\n",
              " 'absolutly',\n",
              " 'absolve',\n",
              " 'absolved',\n",
              " 'absorb',\n",
              " 'absorbed',\n",
              " 'absorbing',\n",
              " 'absorbs',\n",
              " 'absorption',\n",
              " 'absoulely',\n",
              " 'abstain',\n",
              " 'abstinence',\n",
              " 'abstract',\n",
              " 'abstraction',\n",
              " 'abstractions',\n",
              " 'absurd',\n",
              " 'absurder',\n",
              " 'absurdism',\n",
              " 'absurdist',\n",
              " 'absurdities',\n",
              " 'absurdity',\n",
              " 'absurdly',\n",
              " 'absurdness',\n",
              " 'abu',\n",
              " 'abundance',\n",
              " 'abundant',\n",
              " 'abundantly',\n",
              " 'abuse',\n",
              " 'abused',\n",
              " 'abuser',\n",
              " 'abusers',\n",
              " 'abuses',\n",
              " 'abusing',\n",
              " 'abusive',\n",
              " 'abut',\n",
              " 'abuzz',\n",
              " 'aby',\n",
              " 'abysmal',\n",
              " 'abysmally',\n",
              " 'abyss',\n",
              " 'abyssmal',\n",
              " 'ac',\n",
              " 'academic',\n",
              " 'academically',\n",
              " 'academics',\n",
              " 'academy',\n",
              " 'acapulco',\n",
              " 'accapella',\n",
              " 'accede',\n",
              " 'acceded',\n",
              " 'accedes',\n",
              " 'accelerate',\n",
              " 'accelerated',\n",
              " 'acceleration',\n",
              " 'accelerator',\n",
              " 'accent',\n",
              " 'accented',\n",
              " 'accents',\n",
              " 'accentuate',\n",
              " 'accentuated',\n",
              " 'accentuates',\n",
              " 'accentuating',\n",
              " 'accept',\n",
              " 'acceptable',\n",
              " 'acceptably',\n",
              " 'acceptance',\n",
              " 'acceptation',\n",
              " 'accepted',\n",
              " 'acceptence',\n",
              " 'accepting',\n",
              " 'accepts',\n",
              " 'accesible',\n",
              " 'access',\n",
              " 'accessability',\n",
              " 'accessed',\n",
              " 'accessibility',\n",
              " 'accessible',\n",
              " 'accessorizing',\n",
              " 'accessory',\n",
              " 'accidence',\n",
              " 'accident',\n",
              " 'accidental',\n",
              " 'accidentally',\n",
              " 'accidently',\n",
              " 'accidents',\n",
              " 'acclaim',\n",
              " 'acclaimed',\n",
              " 'acclaims',\n",
              " 'acclimate',\n",
              " 'acclimation',\n",
              " 'accolade',\n",
              " 'accolades',\n",
              " 'accommodate',\n",
              " 'accommodated',\n",
              " 'accommodating',\n",
              " 'accommodation',\n",
              " 'accompanied',\n",
              " 'accompanies',\n",
              " 'accompaniment',\n",
              " 'accompany',\n",
              " 'accompanying',\n",
              " 'accomplice',\n",
              " 'accomplices',\n",
              " 'accomplish',\n",
              " 'accomplished',\n",
              " 'accomplishes',\n",
              " 'accomplishing',\n",
              " 'accomplishment',\n",
              " 'accomplishments',\n",
              " 'accord',\n",
              " 'accordance',\n",
              " 'accorded',\n",
              " 'according',\n",
              " 'accordingly',\n",
              " 'accordion',\n",
              " 'accords',\n",
              " 'accorsi',\n",
              " 'accosted',\n",
              " 'accosts',\n",
              " 'account',\n",
              " 'accountable',\n",
              " 'accountant',\n",
              " 'accountants',\n",
              " 'accounted',\n",
              " 'accounting',\n",
              " 'accounts',\n",
              " 'accrued',\n",
              " 'accumulated',\n",
              " 'accumulates',\n",
              " 'accumulating',\n",
              " 'accumulation',\n",
              " 'accuracy',\n",
              " 'accurate',\n",
              " 'accurately',\n",
              " 'accursed',\n",
              " 'accusation',\n",
              " 'accusations',\n",
              " 'accusatory',\n",
              " 'accuse',\n",
              " 'accused',\n",
              " 'accusers',\n",
              " 'accuses',\n",
              " 'accusing',\n",
              " 'accustomed',\n",
              " 'acd',\n",
              " 'ace',\n",
              " 'aced',\n",
              " 'acedemy',\n",
              " 'acedmy',\n",
              " 'acerbic',\n",
              " 'acerbity',\n",
              " 'aces',\n",
              " 'achala',\n",
              " 'acharya',\n",
              " 'ache',\n",
              " 'ached',\n",
              " 'acheived',\n",
              " 'achievable',\n",
              " 'achieve',\n",
              " 'achieved',\n",
              " 'achievement',\n",
              " 'achievements',\n",
              " 'achievers',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBmHShSmqeqf",
        "colab_type": "code",
        "outputId": "3a1c5c07-9537-465f-868b-087a52953ef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "doc_array = count_vector.transform(documents).toarray()\n",
        "doc_array"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j2WFd9urj5j",
        "colab_type": "code",
        "outputId": "f8c4de0d-18c6-4378-f385-62835ba14e0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "source": [
        "frequency_matrix = pd.DataFrame(data=doc_array, columns=names)\n",
        "frequency_matrix.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>000s</th>\n",
              "      <th>001</th>\n",
              "      <th>003830</th>\n",
              "      <th>007</th>\n",
              "      <th>0080</th>\n",
              "      <th>0083</th>\n",
              "      <th>00am</th>\n",
              "      <th>00pm</th>\n",
              "      <th>00s</th>\n",
              "      <th>01</th>\n",
              "      <th>02</th>\n",
              "      <th>020410</th>\n",
              "      <th>03</th>\n",
              "      <th>04</th>\n",
              "      <th>05</th>\n",
              "      <th>050</th>\n",
              "      <th>06</th>\n",
              "      <th>07</th>\n",
              "      <th>08</th>\n",
              "      <th>089</th>\n",
              "      <th>08th</th>\n",
              "      <th>09</th>\n",
              "      <th>0s</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>1000</th>\n",
              "      <th>1000s</th>\n",
              "      <th>1001</th>\n",
              "      <th>100s</th>\n",
              "      <th>100x</th>\n",
              "      <th>100yards</th>\n",
              "      <th>101</th>\n",
              "      <th>101st</th>\n",
              "      <th>102</th>\n",
              "      <th>103</th>\n",
              "      <th>104</th>\n",
              "      <th>1040s</th>\n",
              "      <th>105</th>\n",
              "      <th>...</th>\n",
              "      <th>zsigmond</th>\n",
              "      <th>zu</th>\n",
              "      <th>zubeidaa</th>\n",
              "      <th>zucco</th>\n",
              "      <th>zucker</th>\n",
              "      <th>zuckerman</th>\n",
              "      <th>zucovic</th>\n",
              "      <th>zukhov</th>\n",
              "      <th>zukovic</th>\n",
              "      <th>zulu</th>\n",
              "      <th>zuni</th>\n",
              "      <th>zuniga</th>\n",
              "      <th>zuzz</th>\n",
              "      <th>zvezda</th>\n",
              "      <th>zvyagvatsev</th>\n",
              "      <th>zwick</th>\n",
              "      <th>zwrite</th>\n",
              "      <th>zx81</th>\n",
              "      <th>zy</th>\n",
              "      <th>zyuranger</th>\n",
              "      <th>zzzz</th>\n",
              "      <th>zzzzz</th>\n",
              "      <th>zzzzzzzz</th>\n",
              "      <th>zzzzzzzzzzzz</th>\n",
              "      <th>zÃ©</th>\n",
              "      <th>Ã¡lvaro</th>\n",
              "      <th>Ã¡nd</th>\n",
              "      <th>Ã¡ngel</th>\n",
              "      <th>Ã¢me</th>\n",
              "      <th>Ã¤Ã¤nekoski</th>\n",
              "      <th>Ã©cran</th>\n",
              "      <th>Ã©migrÃ©</th>\n",
              "      <th>Ã©migrÃ©s</th>\n",
              "      <th>Ã©tait</th>\n",
              "      <th>Ã©tat</th>\n",
              "      <th>Ã©tc</th>\n",
              "      <th>Ã©very</th>\n",
              "      <th>Ã­s</th>\n",
              "      <th>Ã­snt</th>\n",
              "      <th>Ã¼ber</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows Ã 51302 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   00  000  000s  001  003830  007  ...  Ã©tat  Ã©tc  Ã©very  Ã­s  Ã­snt  Ã¼ber\n",
              "0   0    0     0    0       0    0  ...     0    0      0   0     0     0\n",
              "1   0    0     0    0       0    0  ...     0    0      0   0     0     0\n",
              "2   0    0     0    0       0    0  ...     0    0      0   0     0     0\n",
              "3   0    0     0    0       0    0  ...     0    0      0   0     0     0\n",
              "4   0    0     0    0       0    0  ...     0    0      0   0     0     0\n",
              "5   0    0     0    0       0    0  ...     0    0      0   0     0     0\n",
              "6   0    0     0    0       0    0  ...     0    0      0   0     0     0\n",
              "7   0    0     0    0       0    0  ...     0    0      0   0     0     0\n",
              "8   0    0     0    0       0    0  ...     0    0      0   0     0     0\n",
              "9   0    0     0    0       0    0  ...     0    0      0   0     0     0\n",
              "\n",
              "[10 rows x 51302 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzQ4f0AuroBr",
        "colab_type": "code",
        "outputId": "f90e6eb0-3618-4ee4-e5fe-62d7652c8605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# split into training and testing sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts_df['texts'], texts_df['labels'], random_state=1)\n",
        "print('Number of rows in the total set: {}'.format(texts_df.shape[0]))\n",
        "print('Number of rows in the training set: {}'.format(X_train.shape[0]))\n",
        "print('Number of rows in the test set: {}'.format(X_test.shape[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows in the total set: 25000\n",
            "Number of rows in the training set: 18750\n",
            "Number of rows in the test set: 6250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioygYY_QsI1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the CountVectorizer method\n",
        "count_vector = CountVectorizer()\n",
        "# Fit the training data and then return the matrix\n",
        "training_data = count_vector.fit_transform(X_train)\n",
        "# Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()\n",
        "testing_data = count_vector.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEbBufHysR4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "naive_bayes = GaussianNB()\n",
        "naive_bayes.fit(training_data.toarray(), y_train)\n",
        "predictions = naive_bayes.predict(testing_data.toarray())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9rdu10_Cz1b",
        "colab_type": "code",
        "outputId": "82357999-9b71-4e73-dd25-248463c57627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(\"Precision: %0.2f\" %precision_score(y_test, predictions , average=\"macro\"))\n",
        "print(\"Recall:  %0.2f\" %recall_score(y_test, predictions , average=\"macro\"))\n",
        "print(\"F1-score:  %0.2f\" %f1_score(y_test, predictions , average=\"macro\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.68\n",
            "Recall:  0.68\n",
            "F1-score:  0.67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhA6N97iab2e",
        "colab_type": "text"
      },
      "source": [
        "### Problem 5 : Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBMcGLNTOaWx",
        "colab_type": "code",
        "outputId": "531b870b-6f71-4cff-a15c-5e68eb0b3970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "LR = LogisticRegression()\n",
        "LR.fit(training_data.toarray(),y_train)\n",
        "pred = LR.predict(testing_data.toarray())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTFh386YUknf",
        "colab_type": "code",
        "outputId": "da295dc0-fc19-48df-a06d-7362064a1943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(\"Precision: %0.2f\" %precision_score(y_test, pred , average=\"macro\"))\n",
        "print(\"Recall:  %0.2f\" %recall_score(y_test, pred , average=\"macro\"))\n",
        "print(\"F1-score:  %0.2f\" %f1_score(y_test, pred , average=\"macro\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.88\n",
            "Recall:  0.88\n",
            "F1-score:  0.88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEN-5D_PZ7j0",
        "colab_type": "text"
      },
      "source": [
        "### Problem 6: \n",
        "Performance is low when we model based on guess work or majority base  and based on baseline length model. That implies that machine learning model works more effective. This can be seen by Performance increases when we use Naive bayes or other classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaTLyzBVaxpp",
        "colab_type": "text"
      },
      "source": [
        "### PRoblem 7: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VarVmbtnvOeZ",
        "colab_type": "code",
        "outputId": "3f00752c-dcbc-46bc-f9ea-ea20be82019e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "### using Pretained word vectors\n",
        "!pip install mxnet\n",
        "import mxnet\n",
        "from mxnet import nd\n",
        "from mxnet.contrib import text\n",
        "\n",
        "text.embedding.get_pretrained_file_names().keys()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/6c/c6e5562f8face683cec73f5d4d74a58f8572c0595d54f1fed9d923020bbd/mxnet-1.5.1.post0-py2.py3-none-manylinux1_x86_64.whl (25.4MB)\n",
            "\u001b[K     |ââââââââââââââââââââââââââââââââ| 25.4MB 1.3MB/s \n",
            "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1 (from mxnet)\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (1.16.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.21.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2019.9.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.5.1.post0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['glove', 'fasttext'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtZxHE_fvglR",
        "colab_type": "code",
        "outputId": "6c0c5a01-8b4b-4bbf-b890-294fc3e02f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(text.embedding.get_pretrained_file_names('glove'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['glove.42B.300d.txt', 'glove.6B.50d.txt', 'glove.6B.100d.txt', 'glove.6B.200d.txt', 'glove.6B.300d.txt', 'glove.840B.300d.txt', 'glove.twitter.27B.25d.txt', 'glove.twitter.27B.50d.txt', 'glove.twitter.27B.100d.txt', 'glove.twitter.27B.200d.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4botkEp9xVdR",
        "colab_type": "text"
      },
      "source": [
        "#### 1- Using \"glove.6B.50d.txt\" as pre-trained Glove embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKxyxHJJvkD5",
        "colab_type": "code",
        "outputId": "df618bed-2908-4ee2-f300-734323053cc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "glove_6b50d = text.embedding.create(\n",
        "    'glove', pretrained_file_name='glove.6B.50d.txt')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.mxnet/embeddings/glove/glove.6B.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/embeddings/glove/glove.6B.zip...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g5IBjuAwD6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def knn(W, x, k):\n",
        "    # The added 1e-9 is for numerical stability\n",
        "    cos = nd.dot(W, x.reshape((-1,))) / (\n",
        "        (nd.sum(W * W, axis=1) + 1e-9).sqrt() * nd.sum(x * x).sqrt())\n",
        "    topk = nd.topk(cos, k=k, ret_typ='indices').asnumpy().astype('int32')\n",
        "    return topk, [cos[i].asscalar() for i in topk]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MwU6sIYwGTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def get_similar_tokens(query_token, k, embed):\n",
        "    topk, cos = knn(embed.idx_to_vec,\n",
        "                    embed.get_vecs_by_tokens([query_token]), k+1)\n",
        "    for i, c in zip(topk[1:], cos[1:]):  # Remove input words\n",
        "        print('cosine sim=%.3f: %s' % (c, (embed.idx_to_token[i])))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZSJmMX0wVlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_analogy(token_a, token_b, token_c, embed):\n",
        "    vecs = embed.get_vecs_by_tokens([token_a, token_b, token_c])\n",
        "    x = vecs[1] - vecs[0] + vecs[2]\n",
        "    topk, cos = knn(embed.idx_to_vec, x, 1)\n",
        "    return embed.idx_to_token[topk[0]] \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1pmpLByoQ53",
        "colab_type": "text"
      },
      "source": [
        "Evaluating embedding glove.6B.50d.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMlyXVHZu6D-",
        "colab_type": "code",
        "outputId": "c2bdfa1c-c916-4c6a-9b35-321892dbac64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#capital-world\n",
        "get_analogy('beijing', 'china', 'tokyo', glove_6b50d)  #capital- world is predicted correctly"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'japan'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-RhvfESiu4V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "5fa6a3cb-3f36-42ff-9b73-c6bc0cc6a38c"
      },
      "source": [
        "sim = glove_model300.n_similarity(['beijing', 'china'], ['tokyo', 'japan'])\n",
        "print(\"{:.4f}\".format(sim))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-RgvFsunRsK",
        "colab_type": "code",
        "outputId": "ad061ceb-eec8-4a04-a951-1200f223386d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#currency\n",
        "get_analogy('algeria', 'dinar', 'japan', glove_6b50d)  #correct is \"yen\""
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'japan'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS5aBrsdjJZD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "a3af183b-ff9d-4959-9435-2e52888c6621"
      },
      "source": [
        "sim = glove_model300.n_similarity(['algeria', 'dinar'], ['japan', 'japan'])\n",
        "print(\"{:.4f}\".format(sim))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1431\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4y_8WsVntAj",
        "colab_type": "code",
        "outputId": "31e379ba-07aa-463d-811f-36ec50204ab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#city-in-state\n",
        "get_analogy('chicago', 'illinois', 'nashville', glove_6b50d) #correct answer is \"Tennessee\""
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'illinois'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maD27tTeaEaG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "a5ec0668-8ea2-4c2c-fd9c-1aa2ece02e14"
      },
      "source": [
        "sim = glove_model300.n_similarity(['chicago', 'illinois'], ['nashville', 'illinois'])\n",
        "print(\"{:.4f}\".format(sim))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8067\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0KIiPaBoffo",
        "colab_type": "code",
        "outputId": "4e255e25-b5a1-427f-9e73-72063003a76e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#family\n",
        "get_analogy('boy ', 'girl', 'son', glove_6b50d) #correct answer is \"daughter\""
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mother'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8tv-DW5jc8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "98226bd2-b147-4184-8385-631afc0cf59a"
      },
      "source": [
        "sim = glove_model300.n_similarity(['boy', 'girl'], ['son', 'mother'])\n",
        "print(\"{:.4f}\".format(sim))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6299\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENGLJkF4ospJ",
        "colab_type": "code",
        "outputId": "4670dca2-1c6d-4c2b-c1da-f18a7378359d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#gram1-adjective-to-adverb\n",
        "get_analogy('apparent', 'apparently', 'cheerful', glove_6b50d) #correct answer is \"cheerfully\"\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cheerful'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlWf-rSrk1A8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "b99a0e09-a2be-48ad-e9a4-be4260801d66"
      },
      "source": [
        "sim = glove_model300.n_similarity(['apparent', 'apparently'], ['cheerful', 'cheerful'])\n",
        "print(\"{:.4f}\".format(sim))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0359\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND7JmeUeo8JT",
        "colab_type": "code",
        "outputId": "8463af7c-29f9-4eb7-8845-b837214b8ba5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# gram2-opposite\n",
        "get_analogy('aware', 'unaware', 'comfortable', glove_6b50d) #correct answer \"uncomfortable\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'comfortable'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhYcFq3Vk91E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "d0e209b2-10d6-4e14-a478-cae7fd283d45"
      },
      "source": [
        "sim = glove_model300.n_similarity(['aware', 'unaware'], ['comfortable', 'comfortable'])\n",
        "print(\"{:.4f}\".format(sim))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2847\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMKdtA4KpUaT",
        "colab_type": "code",
        "outputId": "4fc17f45-4528-4fc6-ebbc-f57f0c1ec3bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# gram3-comparative\n",
        "get_analogy('bad', 'worse', 'easy', glove_6b50d) #correct answer \"easier\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'easy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF2hK4tNlE9f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "e2f1a11a-09c7-48d9-ba5b-d5d1c474f365"
      },
      "source": [
        "sim = glove_model300.n_similarity(['bad', 'worse'], ['easy', 'easy'])\n",
        "print(\"{:.4f}\".format(sim))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3897\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ5mEiF3piLy",
        "colab_type": "code",
        "outputId": "03c98b66-8390-4990-a242-601d2a9680ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#gram6nationality-adjective\n",
        "get_analogy('belarus', 'belorussian', 'norway', glove_6b50d) #correct answer \"Norwegian\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dragoon'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9tWSvoflLDl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "8f88cccd-e979-4cc3-bf6d-eb6114a0e91b"
      },
      "source": [
        "sim = glove_model300.n_similarity(['belarus', 'belorussian'], ['norway', 'dragoon'])\n",
        "print(\"{:.4f}\".format(sim))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2253\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6AZ_AxYxka2",
        "colab_type": "text"
      },
      "source": [
        "#### 2- using glove.6B.100d.txt as pretrained embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8QO8h5LxjTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove_6b100d = text.embedding.create(\n",
        "    'glove', pretrained_file_name='glove.6B.100d.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AUOSFhLtkT5",
        "colab_type": "text"
      },
      "source": [
        "Evaluating embedding glove.6B.100d.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpxku3P6tkwf",
        "colab_type": "code",
        "outputId": "724f9694-db36-490b-bd40-8579d4f619c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#capital-world\n",
        "get_analogy('oslo', 'norway', 'cairo', glove_6b100d)  #capital- world is predicted correctly"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'egypt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D6sM4wAlVAN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "3e8d6abe-fc27-4bf0-b10d-7a0f5a5086fe"
      },
      "source": [
        "sim = glove_model300.n_similarity(['oslo', 'norway'], ['cairo', 'egypt'])\n",
        "print(\"{:.4f}\".format(sim))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c26M_t_Lt4k4",
        "colab_type": "code",
        "outputId": "8281403b-23b6-46c9-f84f-6a1d81dc8633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#currency\n",
        "get_analogy('europe', 'euro', 'brazil', glove_6b100d)  #correct is \"real\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'euro'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY-WsKkElac7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "fe7c3c42-0c1f-4096-fb17-737c7b7ee9a3"
      },
      "source": [
        "sim = glove_model300.n_similarity(['europe', 'euro'], ['brazil', 'euro'])\n",
        "print(\"{:.4f}\".format(sim))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfyWYUzYuRNx",
        "colab_type": "code",
        "outputId": "31657ac9-875e-4f6e-901e-5fa52f8e7b6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#city-in-state\n",
        "get_analogy('dallas', 'texas', 'atlanta', glove_6b100d) #correct answer is \"Georgia\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'texas'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2uKxcN8lfnh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "14cf3a66-f201-4b2c-e720-45fed9b90f78"
      },
      "source": [
        "sim = glove_model300.n_similarity(['dallas', 'texas'], ['atlanta', 'texas'])\n",
        "print(\"{:.4f}\".format(sim))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9NGW2mluduL",
        "colab_type": "code",
        "outputId": "8807bd36-d0e7-486e-a3d6-e903526a9dc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#family\n",
        "get_analogy('boy ', 'girl', 'dad', glove_6b100d) #correct answer is \"mom\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'girl'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO2OUXo_lmmu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "1f42fa5b-03fd-4c45-8914-21f114cc7059"
      },
      "source": [
        "sim = glove_model300.n_similarity(['boy', 'girl'], ['dad', 'girl'])\n",
        "print(\"{:.4f}\".format(sim))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8737\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YijL-Ps0x6b_",
        "colab_type": "code",
        "outputId": "5d7b1900-f05d-4388-ae91-86b7e96bc016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#gram1-adjective-to-adverb\n",
        "get_analogy('free', 'freely', 'calm', glove_6b100d) #correct answer is \"calmly\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'calm'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkeD1HCalnhk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "8303d1e4-a451-4e87-f8db-02002005a48e"
      },
      "source": [
        "sim = glove_model300.n_similarity(['free', 'freely'], ['calm', 'calm'])\n",
        "print(\"{:.4f}\".format(sim))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2109\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xRcb-Stu9YJ",
        "colab_type": "code",
        "outputId": "c6e8dba1-1f00-4051-d6ea-ea2b92b16e16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# gram2-opposite\n",
        "get_analogy('likely', 'unlikely', 'sure', glove_6b100d) #correct answer \"unsure\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sure'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWjmruE7lolX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "aec99d6f-5eaa-4e93-bf2c-0552c4be2def"
      },
      "source": [
        "sim = glove_model300.n_similarity(['likely', 'unlikely'], ['sure', 'sure'])\n",
        "print(\"{:.4f}\".format(sim))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5304\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b35-Ij9fvPHX",
        "colab_type": "code",
        "outputId": "db25ccdf-402f-49e8-b3c3-ffecd90d0bc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# gram3-comparative\n",
        "get_analogy('cheap', 'cheaper', 'old', glove_6b100d) #correct answer \"older\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'old'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u44zsKbAlpP4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "08bd7c28-8eec-4969-b125-6c95b14f5423"
      },
      "source": [
        "sim = glove_model300.n_similarity(['cheap', 'cheaper'], ['old', 'old'])\n",
        "print(\"{:.4f}\".format(sim))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1283\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmYq-HKTvdHo",
        "colab_type": "code",
        "outputId": "cacc9e3b-f882-4148-cf13-0fa8e3eb8917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#gram6nationality-adjective\n",
        "get_analogy('chile', 'chilean', 'france', glove_6b100d) #correctly predicted"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'french'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mswagrH5lqCn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "14c7de39-2e26-47d4-beec-5bb83840cdb2"
      },
      "source": [
        "sim = glove_model300.n_similarity(['chile', 'chilean'], ['france', 'french'])\n",
        "print(\"{:.4f}\".format(sim))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2954\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt5-0Zgy9tPc",
        "colab_type": "code",
        "outputId": "5c032be0-e862-4e87-b0c1-537478de6883",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "import gensim.downloader as api\n",
        "glove_model300 = api.load('glove-wiki-gigaword-300')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-g5sfOb-Sdj",
        "colab_type": "code",
        "outputId": "114f2c3c-f1c9-4a22-8e59-8edc0f9f4ada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        " from gensim.test.utils import datapath\n",
        " analogy_scores = glove_model300.wv.evaluate_word_analogies(datapath('questions-words.txt'))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnJSxg4a8cvN",
        "colab_type": "text"
      },
      "source": [
        "### Probelm 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuJC-olfwqjo",
        "colab_type": "code",
        "outputId": "71ad6579-426a-4880-9db3-f3851941bd5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "get_similar_tokens('increase', 10, glove_6b50d)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cosine sim=0.948: increases\n",
            "cosine sim=0.948: increased\n",
            "cosine sim=0.904: increasing\n",
            "cosine sim=0.892: decrease\n",
            "cosine sim=0.880: reduction\n",
            "cosine sim=0.872: reducing\n",
            "cosine sim=0.868: reduced\n",
            "cosine sim=0.867: growth\n",
            "cosine sim=0.865: reduce\n",
            "cosine sim=0.865: higher\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UDOrh8oHyV6",
        "colab_type": "code",
        "outputId": "099da6c5-bcf8-4e4f-8e4d-5dc23e9dcd38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "get_similar_tokens('white', 10, glove_6b50d)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cosine sim=0.906: black\n",
            "cosine sim=0.874: green\n",
            "cosine sim=0.861: gray\n",
            "cosine sim=0.861: brown\n",
            "cosine sim=0.823: blue\n",
            "cosine sim=0.815: red\n",
            "cosine sim=0.749: colored\n",
            "cosine sim=0.743: orange\n",
            "cosine sim=0.735: bright\n",
            "cosine sim=0.731: dark\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4a9a7X0H6lW",
        "colab_type": "code",
        "outputId": "dfb79a9a-957d-4fb2-ae18-efe9bf7a735e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "get_similar_tokens('negligible', 10, glove_6b50d)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cosine sim=0.801: insignificant\n",
            "cosine sim=0.786: appreciable\n",
            "cosine sim=0.768: decreasing\n",
            "cosine sim=0.766: decrease\n",
            "cosine sim=0.764: attributable\n",
            "cosine sim=0.760: decreases\n",
            "cosine sim=0.755: proportion\n",
            "cosine sim=0.750: discernible\n",
            "cosine sim=0.745: conversely\n",
            "cosine sim=0.728: exceeds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwJs7ebLKIve",
        "colab_type": "text"
      },
      "source": [
        "The reason why Antonyms show up in top 10 similar words is because embedding is based on words that have similar context. Antonyms words have similar context too and that is why the opposite words show up in embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrFJgDkqMBSW",
        "colab_type": "text"
      },
      "source": [
        "### Probelm 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLgpHkGky-Eg",
        "colab_type": "text"
      },
      "source": [
        "Evaluation for glove.6B.50d.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03q_soQ6Ll2f",
        "colab_type": "code",
        "outputId": "1c929b53-2e26-4eb4-ee89-366bbf3572ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#country capital\n",
        "get_analogy('india', 'delhi', 'croatia', glove_6b50d) #correctly predicted"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'zagreb'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPJ8HZcfmYf7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "75561782-2c93-4165-8354-0876e7ca6a95"
      },
      "source": [
        "sim = glove_model300.n_similarity(['india', 'delhi'], ['croatia', 'zagreb'])\n",
        "print(\"{:.4f}\".format(sim))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1677\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ihia00c_MTqT",
        "colab_type": "code",
        "outputId": "5e940592-7980-4ab9-8c34-416a0cd56a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# places-people\n",
        "get_analogy('university', 'students', 'hospital', glove_6b50d)  #correct answer should be \"patients\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'elderly'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSnpYAL9mZ2B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "618f8abb-47a1-47ee-d51d-30711a1d19a5"
      },
      "source": [
        "sim = glove_model300.n_similarity(['university', 'students'], ['hospital', 'elderly'])\n",
        "print(\"{:.4f}\".format(sim))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3711\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItZGLffPMZ6Q",
        "colab_type": "code",
        "outputId": "e23b7e6f-0121-4463-a80a-5c19560a1e31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#opposites\n",
        "get_analogy('wet', 'dry', 'complete', glove_6b50d)   #correct answer should be \"incomplete\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'complete'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPR-M7_Jmada",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "96761f97-ff4c-40d0-9e5f-548e49584df0"
      },
      "source": [
        "sim = glove_model300.n_similarity(['wet', 'dry'], ['complete', 'complete'])\n",
        "print(\"{:.4f}\".format(sim))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0922\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpfXWIKyzBEC",
        "colab_type": "text"
      },
      "source": [
        "Evaluation for glove.6B.100d.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWaXg54TMj5i",
        "colab_type": "code",
        "outputId": "15d937c2-8207-4908-94f4-af7378f5ba8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#country capital\n",
        "get_analogy('greece', 'athens', 'malaysia', glove_6b100d) #correctly predicted"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'kuala'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c07hetUHmbWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "8dd7ad98-168e-4617-d395-d5db3f51bc12"
      },
      "source": [
        "sim = glove_model300.n_similarity(['greece', 'athens'], ['malaysia', 'kuala'])\n",
        "print(\"{:.4f}\".format(sim))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyOKjBf2MtjP",
        "colab_type": "code",
        "outputId": "5ea586b3-6cf2-4815-e24d-1574ffa1beb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#places-people\n",
        "get_analogy('school', 'students', 'zoo', glove_6b100d)  #correct answer should be \"animals\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'zoo'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRJ28CnfmcFL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "76db3c04-62f5-4a51-880b-3610ec05891e"
      },
      "source": [
        "sim = glove_model300.n_similarity(['school', 'students'], ['zoo', 'zoo'])\n",
        "print(\"{:.4f}\".format(sim))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1316\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpze3VTQM4NG",
        "colab_type": "code",
        "outputId": "e73fdedb-94ac-4396-f896-f12e7014818d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "get_analogy('burger', 'eat', 'juice', glove_6b100d)  #answer should be drink"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'juice'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtQ8Hyyomc-6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "10efc714-042a-4474-d344-f9e4d38ddc61"
      },
      "source": [
        "sim = glove_model300.n_similarity(['burger', 'eat'], ['juice', 'juice'])\n",
        "print(\"{:.4f}\".format(sim))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}